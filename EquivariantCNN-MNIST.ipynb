{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from e2cnn import gspaces\n",
    "from e2cnn import nn\n",
    "import sys\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import RandomRotation\n",
    "from torchvision.transforms import Pad\n",
    "from torchvision.transforms import Resize\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C4SteerableCNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes=10):\n",
    "        \n",
    "        super(C4SteerableCNN, self).__init__()\n",
    "        \n",
    "        # the model is equivariant under rotations by 90 degrees, modelled by C4\n",
    "        self.r2_act = gspaces.Rot2dOnR2(N=4)\n",
    "        \n",
    "        # the input image is a scalar field, corresponding to the trivial representation\n",
    "        in_type = nn.FieldType(self.r2_act, [self.r2_act.trivial_repr])\n",
    "        \n",
    "        # to store the input type for wrapping the images into a geometric tensor during the forward pass\n",
    "        self.input_type = in_type\n",
    "        \n",
    "        # convolution 1\n",
    "        # first specify the output type of the convolutional layer\n",
    "        # we choose 24 feature fields, each transforming under the regular representation of C4\n",
    "        out_type = nn.FieldType(self.r2_act, 24*[self.r2_act.regular_repr])\n",
    "        self.block1 = nn.SequentialModule(\n",
    "            nn.MaskModule(in_type, 29, margin=1),\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=7, padding=1, bias=False),\n",
    "            nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type, inplace=True)\n",
    "        )\n",
    "        \n",
    "        #convolution 2\n",
    "        in_type = self.block1.out_type\n",
    "        out_type = nn.FieldType(self.r2_act, 48*[self.r2_act.regular_repr])\n",
    "        \n",
    "        self.block2 = nn.SequentialModule(\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
    "            nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type, inplace=True)\n",
    "        )\n",
    "        self.pool1 = nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=2)\n",
    "        \n",
    "        #convolution 3\n",
    "        in_type = self.block2.out_type\n",
    "        out_type = nn.FieldType(self.r2_act, 48*[self.r2_act.regular_repr])\n",
    "        self.block3 = nn.SequentialModule(\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
    "            nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type, inplace=True)\n",
    "        )\n",
    "        \n",
    "        #convolution 4\n",
    "        in_type = self.block3.out_type\n",
    "        out_type = nn.FieldType(self.r2_act, 96*[self.r2_act.regular_repr])\n",
    "        self.block4 = nn.SequentialModule(\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
    "            nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type, inplace=True)\n",
    "        )\n",
    "        self.pool2 = nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=2)\n",
    "        self.gpool = nn.GroupPooling(out_type)\n",
    "        \n",
    "        # number of output channels\n",
    "        c = self.gpool.out_type.size\n",
    "        \n",
    "        # Fully Connected\n",
    "        self.fully_net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(c*7*7, 64),\n",
    "            torch.nn.BatchNorm1d(64),\n",
    "            torch.nn.ELU(inplace=True),\n",
    "            torch.nn.Linear(64, n_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, input: torch.Tensor):\n",
    "        # wrap the input tensor in a GeometricTensor\n",
    "        # (associate it with the input type)\n",
    "        x = nn.GeometricTensor(input, self.input_type)\n",
    "        \n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # pool over the group\n",
    "        x = self.gpool(x)\n",
    "        # unwrap the output GeometricTensor\n",
    "        # (take the Pytorch tensor and discard the associated representation)\n",
    "        x = x.tensor\n",
    "        \n",
    "        x = self.fully_net(x.reshape(x.shape[0], -1))\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistRotDataset(Dataset):   \n",
    "    def __init__(self, mode, transform=None):\n",
    "        assert mode in ['train', 'test']\n",
    "            \n",
    "        if mode == \"train\":\n",
    "            file = \"mnist_rotation_new/mnist_all_rotation_normalized_float_train_valid.amat\"\n",
    "        else:\n",
    "            file = \"mnist_rotation_new/mnist_all_rotation_normalized_float_test.amat\"\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "        data = np.loadtxt(file, delimiter=' ')\n",
    "            \n",
    "        self.images = data[:, :-1].reshape(-1, 28, 28).astype(np.float32)\n",
    "        self.labels = data[:, -1].astype(np.int64)\n",
    "        self.num_samples = len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.images[index], self.labels[index]\n",
    "        image = Image.fromarray(image)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# images are padded to have shape 29x29.\n",
    "# this allows to use odd-size filters with stride 2 when downsampling a feature map in the model\n",
    "pad = Pad((0, 0, 1, 1), fill=0)\n",
    "\n",
    "# to reduce interpolation artifacts (e.g. when testing the model on rotated images),\n",
    "# we upsample an image by a factor of 3, rotate it and finally downsample it again\n",
    "resize1 = Resize(87)\n",
    "resize2 = Resize(29)\n",
    "\n",
    "# Defining the dataloaders\n",
    "train_transform = Compose([pad, resize1,\n",
    "    RandomRotation(180, resample=Image.BILINEAR, expand=False),\n",
    "    resize2,ToTensor(),])\n",
    "\n",
    "mnist_train = MnistRotDataset(mode='train', transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=64)\n",
    "\n",
    "test_transform = Compose([pad,ToTensor(),])\n",
    "mnist_test = MnistRotDataset(mode='test', transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\w\\1\\s\\tmp_conda_3.7_055457\\conda\\conda-bld\\pytorch_1565416617654\\work\\aten\\src\\ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.\n",
      "C:\\w\\1\\s\\tmp_conda_3.7_055457\\conda\\conda-bld\\pytorch_1565416617654\\work\\aten\\src\\ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "model = C4SteerableCNN().to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch numer 0 | Batch number 0| Loss: tensor(2.5043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 5| Loss: tensor(2.1237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 10| Loss: tensor(1.9712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 15| Loss: tensor(1.7131, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 20| Loss: tensor(1.7183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 25| Loss: tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 30| Loss: tensor(1.6867, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 35| Loss: tensor(1.5074, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 40| Loss: tensor(1.4283, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 45| Loss: tensor(1.2501, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 50| Loss: tensor(1.4005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 55| Loss: tensor(1.2882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 60| Loss: tensor(1.3414, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 65| Loss: tensor(1.1634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 70| Loss: tensor(1.1979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 75| Loss: tensor(1.3533, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 80| Loss: tensor(1.2117, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 85| Loss: tensor(1.1772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 90| Loss: tensor(1.0423, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 95| Loss: tensor(1.0999, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 100| Loss: tensor(0.9966, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 105| Loss: tensor(0.9376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 110| Loss: tensor(0.9831, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 115| Loss: tensor(0.9277, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 120| Loss: tensor(0.9866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 125| Loss: tensor(1.0155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 130| Loss: tensor(1.0078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 135| Loss: tensor(0.9320, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 140| Loss: tensor(0.8888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 145| Loss: tensor(0.7654, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 150| Loss: tensor(0.7980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 155| Loss: tensor(0.7211, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 160| Loss: tensor(0.8431, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 165| Loss: tensor(0.9049, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 170| Loss: tensor(0.8460, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 175| Loss: tensor(0.8211, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 180| Loss: tensor(0.9053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 0 | Batch number 185| Loss: tensor(0.7886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 1 | Batch number 0| Loss: tensor(0.7856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 1 | Batch number 5| Loss: tensor(0.9330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch numer 1 | Batch number 10| Loss: tensor(0.7728, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-3d1360944e4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     99\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_exp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(31):\n",
    "    model.train()\n",
    "    for i, (x, t) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "\n",
    "        y = model(x)\n",
    "        #sys.exit()\n",
    "\n",
    "        loss = loss_function(y, t)\n",
    "        if i%5==0:\n",
    "            print(f\"Epoch numer {epoch} | Batch number {i}| Loss:\",loss)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % 5 == 1:\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for i, (x, t) in enumerate(test_loader):\n",
    "\n",
    "                x = x.to(device)\n",
    "                t = t.to(device)\n",
    "                \n",
    "                y = model(x)\n",
    "\n",
    "                _, prediction = torch.max(y.data, 1)\n",
    "                total += t.shape[0]\n",
    "                correct += (prediction == t).sum().item()\n",
    "        print(f\"After epoch {epoch} | Test accuracy: {correct/total*100.}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
